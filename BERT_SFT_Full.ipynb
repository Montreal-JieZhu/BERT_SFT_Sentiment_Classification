{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c037ed91-001c-4abf-b49b-bc9007be27f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### In this section, I Fine-tuned a pretrained BERT model on the IMDB dataset for sentiment analysis, evaluate it with accuracy / F1, and run inference using the Hugging Face Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bcea47c-0b22-4f4f-b8fc-0bfaad24e926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pip install transformers datasets evaluate accelerate scikit-learn\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding, Trainer, TrainingArguments)\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd6f637b-493c-4e1c-bde5-1e039cb56d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- GPU / Mixed-Precision setup ---\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_bf16 = use_cuda and torch.cuda.is_bf16_supported()     # Ampere+ GPUs\n",
    "use_fp16 = use_cuda and not use_bf16                       # fallback to fp16 if bf16 not available\n",
    "print(f\"CUDA available: {use_cuda} | bf16: {use_bf16} | fp16: {use_fp16} | GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe92cee0-553c-4793-a426-cc9952f9e046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "NUM_LABELS = 2  # binary classification\n",
    "\n",
    "# 1) Data: IMDB (binary sentiment)\n",
    "dataset = load_dataset(\"imdb\")  # splits: train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc936f1d-8d16-46a0-81b2-bea58e1d7455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85d83014-d19a-4148-b6ff-9688517dfae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"test\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a329d67-6bfe-47a4-8ee3-68bab12c0bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"][50:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6758860-39f0-4f6f-8317-64061a270c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"unsupervised\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61dfd019-82d5-4794-864a-13ca746f78d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### SFT needs labeled data. So removing unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07b8dd58-cc9f-4479-b473-c7cf75d38648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "del dataset[\"unsupervised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5ac1cd7-f6f6-4c73-91a2-64f3323910ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2) Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ed9e3b2-24fb-40ed-8969-a464f7b2cb8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbd05650-09ee-479e-bb6b-cfea9e1f4a85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Tokenizing the text based on its vocab so that machine can process it.\n",
    "##### Models like BERT or GPT don’t read English words the way humans do. They can only process numbers — so we must first convert text into numbers that the model can understand. That’s what tokenization and token IDs do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5b6bab4-1d41-4917-993d-183c2a5c82b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "567a038c-ae13-4cac-939e-a7db3b0bf95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25ddcb5b-63db-4da5-a95d-fd0c7bc5d92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3) Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af16cadc-5778-46b9-ba53-d049d8be719e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: reduce memory on large batches\n",
    "if use_cuda:\n",
    "    model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83cfb7c4-99a2-4147-990d-65574fbbc10b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4) Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c67b9ad1-8461-4184-86cf-fe2972d5013f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa3683be-3e63-46e0-9289-5393f82fabaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5) Training config (GPU-aware)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"bert-imdb\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,   # adjust up if you have more GPU memory\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    bf16=use_bf16,                    # mixed precision on Ampere+ (preferred)\n",
    "    fp16=use_fp16,                    # else use fp16\n",
    "    dataloader_pin_memory=True,\n",
    "    optim=\"adamw_torch\",              # fast fused AdamW in recent PyTorch\n",
    "    torch_compile=True if use_cuda and torch.__version__.startswith(\"2.\") else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4373179-b283-4d19-93e7-0683fbf89874",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6) Trainer (Trainer uses GPU automatically if available)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "307dd7bd-e680-495b-a5a6-3aea3381df72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "807ad44b-2211-4439-8564-11d6055a3c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7) Save + quick inference\n",
    "trainer.save_model(\"bert-imdb/best\")\n",
    "tokenizer.save_pretrained(\"bert-imdb/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52e8ed1f-0032-47da-8212-ad649239a2dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Sample sentences for comparison\n",
    "sentences = [\n",
    "    \"This movie was absolutely wonderful!\",\n",
    "    \"The story was slow and boring.\",\n",
    "    \"I didn’t expect it to be so emotional.\",\n",
    "    \"Terrible plot and wooden acting.\",\n",
    "    \"I hope the actors can work harder.\",\n",
    "    \"I hope to watch next season.\",\n",
    "    \"It is waste of money to watch this movie!\"\n",
    "]\n",
    "\n",
    "# 1️⃣ Baseline: pretrained BERT (before fine-tuning)\n",
    "base_clf = pipeline(\"text-classification\", model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\", device_map=\"auto\")\n",
    "print(\"=== Predictions from base BERT (before fine-tuning) ===\")\n",
    "for s in sentences:\n",
    "    print(f\"{s} -> {base_clf(s)}\")\n",
    "\n",
    "# 2️⃣ Fine-tuned model\n",
    "fine_tuned_clf = pipeline(\"text-classification\", model=\"bert-imdb/best\", tokenizer=\"bert-imdb/best\", device_map=\"auto\")\n",
    "print(\"\\n=== Predictions from fine-tuned BERT (after fine-tuning) ===\")\n",
    "for s in sentences:\n",
    "    print(f\"{s} -> {fine_tuned_clf(s)}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BERT_SFT_Full",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
